{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633b34c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from embedding_model import Embedder\n",
    "import chromadb\n",
    "import torch\n",
    "import hashlib\n",
    "\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b872f91",
   "metadata": {},
   "source": [
    "##### USE HASH library for persistent ids assignment\n",
    "\n",
    "https://cookbook.chromadb.dev/core/document-ids/#hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "029bb73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sha256_hash_from_text(text):\n",
    "    # Create a SHA256 hash object\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    # Update the hash object with the text encoded to bytes\n",
    "    sha256_hash.update(text.encode('utf-8'))\n",
    "    # Return the hexadecimal representation of the hash\n",
    "    return sha256_hash.hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3beaf210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3eb787d0b3d7fe92710642d8b377187a8f320eaf6d6e4e015d2a5a150477c8bf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sha256_hash_from_text(\"Hello Worl3232d!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b5fba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_multiple_query(query, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": SYSTEM_PROMT_QUERY_EXPANSION,\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    content = content.split(\"\\n\")\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f37cf0",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "\n",
    "```bash\n",
    "docker run tinyrag --persistent_storage [path]  \n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "docker-compose up\n",
    "```\n",
    "### This should deploys a RAG API with 4 endpoints:\n",
    "\n",
    " - /tinyrag/upload_file\n",
    " \n",
    " - /tinyrag/upload_zip\n",
    " \n",
    " - /tinyrag/query$?expand\n",
    " \n",
    " - /tinyrag/reset\n",
    " \n",
    " \n",
    " Think more about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1b90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdfChunksLoader_ChromaDB():\n",
    "    def __init__(self, collection, embedder, text_splitter=None):\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.collection = collection\n",
    "        self.embedder = embedder\n",
    "        self.id = 0\n",
    "        self.text_splitter = text_splitter if text_splitter else RecursiveCharacterTextSplitter(chunk_size=1500, \n",
    "                                                                           chunk_overlap=100,\n",
    "                                                                           separators=[\"\\n\", \"\\t\", \".\", \",\", \" \", \"\"],)\n",
    "        \n",
    "        \n",
    "    def _extract_pdf_chunks(self, path):\n",
    "        \n",
    "        loader = PyPDFLoader(path)\n",
    "        \n",
    "        chunks = loader.load_and_split(text_splitter=self.text_splitter)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def _get_chunk_id(self, chunk):\n",
    "        \n",
    "        return \"chunkID_\" + generate_sha256_hash_from_text(chunk.page_content)\n",
    "        \n",
    "    def filter_existing_docs(self, docs_ids_map):\n",
    "        \n",
    "        \n",
    "        ids_computed = list(docs_ids_map.keys())\n",
    "        \n",
    "            \n",
    "        existing_chunks_ids = rag.collection.get(ids=ids_computed)[\"ids\"]\n",
    "        \n",
    "        \n",
    "        def extract_only_new_docs(keyval_tuple):\n",
    "            key, value = keyval_tuple\n",
    "            \n",
    "            return (key not in existing_chunks_ids)\n",
    "            \n",
    "        filtered_docs_map = dict(filter(extract_only_new_docs,  docs_ids_map.items()))\n",
    "        \n",
    "        return filtered_docs_map\n",
    "        \n",
    "        \n",
    "    \n",
    "    def populate(self, documents):\n",
    "        ##TODO: add batch size for computing embeddings\n",
    "        \n",
    "        ### try to add one by one to avoid redundant computing of embedds\n",
    "        \n",
    "        \n",
    "        #check filter ids\n",
    "        \n",
    "        ids_computed = [self._get_chunk_id(chunk) for chunk in documents]\n",
    "        \n",
    "        docs_id_map = {uri_id : doc for uri_id, doc in zip(ids_computed, documents)}\n",
    "        \n",
    "        filtered_docs_id_map = self.filter_existing_docs(docs_id_map)\n",
    "        \n",
    "        if (filtered_docs_id_map):\n",
    "            self.collection.add(\n",
    "                documents=[chunk.page_content for chunk in filtered_docs_id_map.values()],\n",
    "\n",
    "                metadatas = [chunk.metadata for chunk in filtered_docs_id_map.values()],\n",
    "\n",
    "                embeddings = self.embedder.compute_embeddings([chunk.page_content for chunk in filtered_docs_id_map.values()]).tolist(),\n",
    "                ids = [doc_id for doc_id in filtered_docs_id_map.keys()]\n",
    "\n",
    "                )\n",
    "        else:\n",
    "            print(\"Documents already exist...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b7d4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RetrievalAugmentedGenerator():\n",
    "    def __init__(self, db_client, embedder, collection_name):\n",
    "        \n",
    "        self.db_client = db_client\n",
    "        self.embedder = embedder\n",
    "        \n",
    "        self.collection_name = collection_name\n",
    "        self.collection = self.db_client.get_or_create_collection(name=self.collection_name)\n",
    "        \n",
    "        self.chunk_loader = PdfChunksLoader_ChromaDB(self.collection,\n",
    "                                                     embedder)\n",
    "\n",
    "    def upload_pdf_file(self, path_file, batch_size=5):\n",
    "        ##Load chunks by batches\n",
    "        \n",
    "        docs = self.chunk_loader._extract_pdf_chunks(path_file)\n",
    "        \n",
    "        for i in tqdm(range(math.ceil(len(docs) / batch_size)), desc=f\"[{path_file}] loading batches:\"):\n",
    "            self.chunk_loader.populate(docs[i * batch_size : (i + 1) * batch_size])\n",
    "        \n",
    "        \n",
    "        print(f\"[{path_file}]: All batches loaded successfully...\")\n",
    "    \n",
    "    def query_with_embeddings(self, embeddings, top_k):\n",
    "        \n",
    "        return self.collection.query(query_embeddings=embeddings,\n",
    "                                      n_results=top_k)\n",
    "    \n",
    "    def query_with_text(self, queries, top_k):\n",
    "        \n",
    "        #compute embeddings\n",
    "        \n",
    "        embeddings_tensor = self.embedder.compute_embeddings(queries)\n",
    "        embeddings_list = embeddings_tensor.tolist()\n",
    "        \n",
    "        \n",
    "        return self.query_with_embeddings(embeddings_list, top_k)\n",
    "    \n",
    "    \n",
    "    def get(self, ids, where, limit):\n",
    "        pass\n",
    "    \n",
    "    def reset_collection(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53e57506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#db_client = chromadb.PersistentClient(path=\"./persistent_storage\")\n",
    "\n",
    "db_client = chromadb.HttpClient(host=\"localhost\", port=8000)\n",
    "\n",
    "#collection = db_client.get_collection(\"my_collection\")\n",
    "embedder =  Embedder(model_name='sentence-transformers/all-MiniLM-L12-v2',\n",
    "                    tokenizer_name='sentence-transformers/all-MiniLM-L12-v2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "275ca438",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = RetrievalAugmentedGenerator(db_client, embedder, \"default_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85a34fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[library/pthreads.pdf] loading batches:: 100%|██| 14/14 [01:06<00:00,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[library/pthreads.pdf]: All batches loaded successfully...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rag.upload_pdf_file(\"library/pthreads.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ced55eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c66476e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['chunkID_c3613574763888c3b28c699e2a8fa21004cfc74ac352ab83df9035ad6e9e7b7f',\n",
       "   'chunkID_56dfddbcb19ae4d535a82c302dc4faa812b64bd3f3dd00cf192d7b0c3f1aceba',\n",
       "   'chunkID_c9cb4bedf5d6e8b5a4ad72df13f5d80a98054dd304c1ae6ff559fd5ae912b9c7'],\n",
       "  ['chunkID_8d6f1a32111a6052e0f502c611a5a4f968071da4ca9378a1a2462fd90c08b611',\n",
       "   'chunkID_3bad18de465ac18c3c4bff592f1585e93c374922f724abf02c6eb91ba345f376',\n",
       "   'chunkID_f21b8a38a47df7701d585fc11541f74988f9f9a32a8862e39f13e8b442923e51']],\n",
       " 'distances': [[0.5447016473704277, 0.6239121965415511, 0.6412980707355009],\n",
       "  [0.9459152660459222, 0.9747333002740871, 1.0722717537353825]],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [[{'page': 18, 'source': 'library/pthreads.pdf'},\n",
       "   {'page': 22, 'source': 'library/pthreads.pdf'},\n",
       "   {'page': 19, 'source': 'library/pthreads.pdf'}],\n",
       "  [{'page': 18, 'source': 'library/pthreads.pdf'},\n",
       "   {'page': 19, 'source': 'library/pthreads.pdf'},\n",
       "   {'page': 25, 'source': 'library/pthreads.pdf'}]],\n",
       " 'documents': [['it to pthread_mutex_init .The second argument to pthread_mutex_init is a pointer \\nto a mutex attribute object, which specifies attributes of the mutex.As with05 0430 CH04  5/22/01  10:21 AM  Page 79',\n",
       "   '83 4.4 Synchronization and Critical Sections\\nAs suggested by the “np”suffix, the recursive and error-checking mutex kinds are spe-\\ncific to GNU/Linux and are not portable.Therefore, it is generally not advised to usethem in programs. (Error-checking mutexes can be useful when debugging, though.) \\n4.4.4 Nonblocking Mutex Tests\\nOccasionally, it is useful to test whether a mutex is locked without actually blockingon it. For instance, a thread may need to lock a mutex but may have other work to doinstead of blocking if the mutex is already locked. Because \\npthread_mutex_lock will\\nnot return until the mutex becomes unlocked, some other function is necessary.\\nGNU/Linux provides pthread_mutex_trylock for this purpose. If you call\\npthread_mutex_trylock on an unlocked mutex, you will lock the mutex as if you had\\ncalled pthread_mutex_lock , and pthread_mutex_trylock will return zero. However, if\\nthe mutex is already locked by another thread, pthread_mutex_trylock will not block.\\nInstead, it will return immediately with the error code EBUSY .The mutex lock held by\\nthe other thread is not affected.Y ou may try again later to lock the mutex.\\n4.4.5 Semaphores for Threads',\n",
       "   '80 Chapter 4 Threads\\npthread_create , if the attribute pointer is null, default attributes are assumed.The\\nmutex variable should be initialized only once.This code fragment demonstrates thedeclaration and initialization of a mutex variable.\\npthread_mutex_t mutex;pthread_mutex_init (&mutex, NULL);\\nAnother simpler way to create a mutex with default attributes is to initialize it with the special value \\nPTHREAD_MUTEX_INITIALIZER . No additional call to\\npthread_mutex_init is necessary.This is particularly convenient for global variables\\n(and, in C++, static data members).The previous code fragment could equivalentlyhave been written like this:\\npthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\\nA thread may attempt to lock a mutex by calling pthread_mutex_lock on it. If the\\nmutex was unlocked, it becomes locked and the function returns immediately. If themutex was locked by another thread,\\npthread_mutex_lock blocks execution and\\nreturns only eventually when the mutex is unlocked by the other thread. More thanone thread may be blocked on a locked mutex at one time.When the mutex isunlocked, only one of the blocked threads (chosen unpredictably) is unblocked andallowed to lock the mutex; the other threads stay blocked.\\nA call to \\npthread_mutex_unlock unlocks a mutex.This function should always be\\ncalled from the same thread that locked the mutex.\\nListing 4.11 shows another version of the job queue example. Now the queue is'],\n",
       "  ['job_queue ; if it’s not empty,\\nremove the first job, all as a single atomic operation.\\n4.4.2 Mutexes\\nThe solution to the job queue race condition problem is to let only one thread accessthe queue of jobs at a time. Once a thread starts looking at the queue, no other threadshould be able to access it until the first thread has decided whether to process a joband, if so, has removed the job from the list.\\nImplementing this requires support from the operating system. GNU/Linux pro-\\nvides mutexes , short for MUTual EXclusion locks .A mutex is a special lock that only one\\nthread may lock at a time. If a thread locks a mutex and then a second thread also triesto lock the same mutex, the second thread is blocked , or put on hold. Only when the\\nfirst thread unlocks the mutex is the second thread unblocked —allowed to resume \\nexecution. GNU/Linux guarantees that race conditions do not occur among threadsattempting to lock a mutex; only one thread will ever get the lock, and all otherthreads will be blocked.\\nThink of a mutex as the lock on a lavatory door.Whoever gets there first enters the\\nlavatory and locks the door. If someone else attempts to enter the lavatory while it ’s\\noccupied, that person will find the door locked and will be forced to wait outsideuntil the occupant emerges.\\nT o create a mutex, create a variable of type \\npthread_mutex_t and pass a pointer to\\nit to pthread_mutex_init .The second argument to pthread_mutex_init is a pointer',\n",
       "   'Listing 4.11 shows another version of the job queue example. Now the queue is\\nprotected by a mutex. Before accessing the queue (either for read or write), eachthread locks a mutex first. Only when the entire sequence of checking the queue andremoving a job is complete is the mutex unlocked.This prevents the race conditionpreviously described.\\nListing 4.11 (job-queue2.c ) Job Queue Thread Function, Protected by a Mutex\\n#include <malloc.h>#include <pthread.h>struct job {\\n/* Link field for linked list.  */struct job* next; /* Other fields describing work to be done... */\\n};/* A linked list of pending jobs.  */struct job* job_queue;/* A mutex protecting job_queue.  */pthread_mutex_t job_queue_mutex = PTHREAD_MUTEX_INITIALIZER;05 0430 CH04  5/22/01  10:21 AM  Page 80',\n",
       "   'We’ve shown how to use a mutex to protect a variable against simultaneous access by\\ntwo threads and how to use semaphores to implement a shared counter.A condition\\nvariable is a third synchronization device that GNU/Linux provides; with it, you can\\nimplement more complex conditions under which threads execute.\\nSuppose that you write a thread function that executes a loop infinitely, performing\\nsome work on each iteration.The thread loop, however, needs to be controlled by aflag:The loop runs only when the flag is set; when the flag is not set, the loop pauses.\\nListing 4.13 shows how you might implement this by spinning in a loop. During\\neach iteration of the loop, the thread function checks that the flag is set. Because theflag is accessed by multiple threads, it is protected by a mutex.This implementationmay be correct, but it is not efficient.The thread function will spend lots of CPUListing 4.12 Continued05 0430 CH04  5/22/01  10:21 AM  Page 86']]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.query_with_text([\"What is mutex used for in threads?\", \"Avoiding Data Race by locking\"], top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb640fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
