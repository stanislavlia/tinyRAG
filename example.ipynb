{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3529c187",
   "metadata": {},
   "source": [
    "https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f394ba",
   "metadata": {},
   "source": [
    "https://learn.deeplearning.ai/courses/knowledge-graphs-rag/lesson/5/constructing-a-knowledge-graph-from-text-documents\n",
    "\n",
    "https://learn.deeplearning.ai/courses/advanced-retrieval-for-ai/lesson/1/introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9060df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding_model import Embedder\n",
    "import chromadb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6bf44c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 12:07:30.871025: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-15 12:07:32.848799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "embedder = Embedder(model_name='sentence-transformers/all-MiniLM-L12-v2',\n",
    "                    tokenizer_name='sentence-transformers/all-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32c2a1b",
   "metadata": {},
   "source": [
    "### Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0a3c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Name: chromadb\n",
      "Version: 0.4.9\n",
      "Summary: Chroma.\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Jeff Huber <jeff@trychroma.com>, Anton Troynikov <anton@trychroma.com>\n",
      "License: \n",
      "Location: /home/stanislav/.local/lib/python3.10/site-packages\n",
      "Requires: bcrypt, chroma-hnswlib, fastapi, importlib-resources, numpy, onnxruntime, overrides, posthog, pulsar-client, pydantic, pypika, requests, tokenizers, tqdm, typing-extensions, uvicorn\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip3 show chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a562f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "db_client = chromadb.PersistentClient(path=\"./persistent_storage\")\n",
    "\n",
    "collection = db_client.get_collection(\"my_collection\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1e640ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Adding docs\n",
    "\n",
    "# collection.add(\n",
    "    \n",
    "    \n",
    "#     documents=docs,\n",
    "#     metadatas=[{\"len\" : len(docs[0]), \"uri\" : 232},\n",
    "#                {\"len\" : len(docs[1]), \"uri\" : 235},\n",
    "#               {\"len\" : len(docs[2]), \"uri\" : 239}],\n",
    "    \n",
    "#    ids=[\"uri9\", \"uri10\", \"uri12\"],\n",
    "    \n",
    "#     embeddings=[ \n",
    "#                 [0.1, 0.3, 0.4],\n",
    "#                  [-0.1, 0.3, 0.5],\n",
    "#                  [2, 0, 0.03]  \n",
    "#                             ]\n",
    "        \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdfbc8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['uri9', 'uri10'],\n",
       " 'embeddings': [[0.10000000149011612, 0.30000001192092896, 0.4000000059604645],\n",
       "  [-0.10000000149011612, 0.30000001192092896, 0.5]],\n",
       " 'metadatas': [{'len': 28, 'uri': 232}, {'len': 35, 'uri': 235}],\n",
       " 'documents': ['Hello World! My name is Stas',\n",
       "  'Let me introduce my self, I am Stas']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.peek(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77da761f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['uri12', 'uri9']],\n",
       " 'distances': [[0.16290000040233138, 3.6157999958872797]],\n",
       " 'metadatas': [[{'len': 40, 'uri': 239}, {'len': 28, 'uri': 232}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['A white cat has eaten and now he is full',\n",
       "   'Hello World! My name is Stas']]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query([[2, 0.27, 0.33],],\n",
    "                 n_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90af0b3d",
   "metadata": {},
   "source": [
    "### Rough plan \n",
    "\n",
    "ChromaDB + TextEmbedding + ChatGPT3 + Custom Promts and chains + Web UI (optional)\n",
    "\n",
    "\n",
    "\n",
    "- application takes path to directory with pdfs as argument\n",
    "- split docs into chunks + add metadata\n",
    "- compute embeddings and put chunks to Chroma\n",
    "- Create chains for Q&A that uses metada and refers to uris of docs\n",
    "- put app to Docker container\n",
    "- Query expansion + Cross-Encoder re-ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eadae6",
   "metadata": {},
   "source": [
    "## OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66615973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fc26dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Make up a poem about Deep Learning.\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28ae9a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of data and of code,\n",
      "Where machines learn to take the load,\n",
      "Deep Learning rises like a star,\n",
      "Unfolding patterns near and far.\n",
      "\n",
      "Hidden layers, neurons fire,\n",
      "Mapping inputs to desired higher,\n",
      "Through iterations and backpropagation,\n",
      "It refines its own creation.\n",
      "\n",
      "Images, text, and sounds it sees,\n",
      "Extracting meaning with ease,\n",
      "Pattern recognition never dull,\n",
      "In the deep, it finds the pull.\n",
      "\n",
      "Complex tasks it can embrace,\n",
      "Unraveling data's intricate maze,\n",
      "With each epoch, it grows stronger,\n",
      "A digital mind, lasting longer.\n",
      "\n",
      "So let us marvel at this wonder,\n",
      "Of algorithms tearing asunder,\n",
      "The boundaries of what we know,\n",
      "Deep Learning, in its brilliance, shows.\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095fcd25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
